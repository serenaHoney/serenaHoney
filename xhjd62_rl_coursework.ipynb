{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serenaHoney/serenaHoney/blob/main/xhjd62_rl_coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEiP6QsOZ9ch"
      },
      "source": [
        "# Coursework Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTNU1mwGB1ZD"
      },
      "source": [
        "**Dependencies and imports**\n",
        "\n",
        "This can take a minute..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yyyDQxZAZ9ck",
        "outputId": "e2a17c44-2af6-4362-f5ae-71bc5da55c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: rldurham in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from rldurham) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from rldurham) (7.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from rldurham) (2.32.3)\n",
            "Requirement already satisfied: gymnasium[Box2D,atari,other] in /usr/local/lib/python3.11/dist-packages (from rldurham) (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from rldurham) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rldurham) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rldurham) (1.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rldurham) (2.2.2)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (from rldurham) (2.5.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (0.10.2)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (4.3.0)\n",
            "Requirement already satisfied: moviepy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (1.0.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (4.11.0.86)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from gymnasium[Box2D,atari,other]->rldurham) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->rldurham) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->rldurham) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->rldurham) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->rldurham) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->rldurham) (3.0.13)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (2025.3.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (0.14.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (24.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (1.7.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (4.67.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning->rldurham) (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->rldurham) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->rldurham) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rldurham) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rldurham) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rldurham) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->rldurham) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->rldurham) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->rldurham) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->rldurham) (2025.1.31)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (3.11.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->rldurham) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->rldurham) (0.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->gymnasium[Box2D,atari,other]->rldurham) (3.2.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->gymnasium[Box2D,atari,other]->rldurham) (0.1.11)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->gymnasium[Box2D,atari,other]->rldurham) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->gymnasium[Box2D,atari,other]->rldurham) (0.6.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->rldurham) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->rldurham) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->rldurham) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->rldurham) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->rldurham) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->rldurham) (1.18.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->rldurham) (5.7.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->rldurham) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->rldurham) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install --upgrade rldurham"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_UnMjDlZ9cl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Normal\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rldurham as rld\n",
        "\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWSAcvIfckbl"
      },
      "source": [
        "## Using a deep, dense D2RL Q-network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-4vQy7RxiBR"
      },
      "outputs": [],
      "source": [
        "# D2RLQNetwork code implemented from https://github.com/pairlab/d2rl/blob/main/sac/model.py\n",
        "\n",
        "\n",
        "def weights_init_(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class D2RLQNetwork(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_inputs,\n",
        "                 num_actions,\n",
        "                 hidden_dim,\n",
        "                 num_layers=3):\n",
        "        super(D2RLQNetwork, self).__init__()\n",
        "\n",
        "        in_dim = num_inputs + num_actions + hidden_dim\n",
        "        # Q architecture\n",
        "        self.l1_1 = nn.Linear(num_inputs + num_actions, hidden_dim)\n",
        "        self.l1_2 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        if num_layers > 2:\n",
        "            self.l1_3 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.l1_4 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        if num_layers > 4:\n",
        "            self.l1_5 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.l1_6 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        if num_layers == 8:\n",
        "            self.l1_7 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.l1_8 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        self.apply(weights_init_)\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, input):\n",
        "        xu = input\n",
        "\n",
        "        x1 = F.relu(self.l1_1(xu))\n",
        "        x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "        x1 = F.relu(self.l1_2(x1))\n",
        "        if self.num_layers > 2:\n",
        "            x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "        if self.num_layers > 2:\n",
        "            x1 = F.relu(self.l1_3(x1))\n",
        "            x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "            x1 = F.relu(self.l1_4(x1))\n",
        "            if self.num_layers > 4:\n",
        "                x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "        if self.num_layers > 4:\n",
        "            x1 = F.relu(self.l1_5(x1))\n",
        "            x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "            x1 = F.relu(self.l1_6(x1))\n",
        "            if self.num_layers > 6:\n",
        "                x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "        if self.num_layers == 8:\n",
        "            x1 = F.relu(self.l1_7(x1))\n",
        "            x1 = torch.cat([x1, xu], dim=1)\n",
        "\n",
        "            x1 = F.relu(self.l1_8(x1))\n",
        "\n",
        "        x1 = self.out(x1)\n",
        "\n",
        "        return x1\n",
        "\n",
        "    def weights_init_(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "            torch.nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxP-c5xed9D7"
      },
      "source": [
        "D2RL Actor (Gaussian Policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDtg_BTQxiBS"
      },
      "outputs": [],
      "source": [
        "# code implemented from https://github.com/pairlab/d2rl/blob/main/sac/model.py\n",
        "\n",
        "\n",
        "class D2RLGaussianPolicy(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_inputs,\n",
        "                 num_actions,\n",
        "                 maximum_action,\n",
        "                 hidden_dim,\n",
        "                 hidden_activation,\n",
        "                 action_bound_epsilon,\n",
        "                 log_sig_min,\n",
        "                 log_sig_max,\n",
        "                 act_space,\n",
        "                 num_layers=3,\n",
        "                 ):\n",
        "        super(D2RLGaussianPolicy, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.action_bound_epsilon = action_bound_epsilon\n",
        "        self.log_sig_min = log_sig_min\n",
        "        self.log_sig_max = log_sig_max\n",
        "\n",
        "        in_dim = hidden_dim+num_inputs\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
        "        self.linear2 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "\n",
        "        if num_layers > 2:\n",
        "            self.linear3 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.linear4 = nn.Linear(in_dim, hidden_dim)\n",
        "        if num_layers > 4:\n",
        "            self.linear5 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.linear6 = nn.Linear(in_dim, hidden_dim)\n",
        "        if num_layers == 8:\n",
        "            self.linear7 = nn.Linear(in_dim, hidden_dim)\n",
        "            self.linear8 = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.mean_linear = nn.Linear(hidden_dim, num_actions)\n",
        "        self.log_std_linear = nn.Linear(hidden_dim, num_actions)\n",
        "\n",
        "        self.apply(weights_init_)\n",
        "\n",
        "        # action rescaling\n",
        "        if act_space is None:\n",
        "            self.action_scale = torch.tensor(1.)\n",
        "            self.action_bias = torch.tensor(0.)\n",
        "        else:\n",
        "            self.action_scale = torch.FloatTensor(\n",
        "                (act_space.high - act_space.low) / 2.).to(device)\n",
        "            self.action_bias = torch.FloatTensor(\n",
        "                (act_space.high + act_space.low) / 2.).to(device)\n",
        "\n",
        "    def forward(self, state, deterministic=False,\n",
        "        with_log_prob=True,):\n",
        "        x = F.relu(self.linear1(state))\n",
        "        x = torch.cat([x, state], dim=1)\n",
        "\n",
        "        x = F.relu(self.linear2(x))\n",
        "\n",
        "        if self.num_layers > 2:\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear3(x))\n",
        "\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear4(x))\n",
        "\n",
        "        if self.num_layers > 4:\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear5(x))\n",
        "\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear6(x))\n",
        "\n",
        "        if self.num_layers == 8:\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear7(x))\n",
        "\n",
        "            x = torch.cat([x, state], dim=1)\n",
        "            x = F.relu(self.linear8(x))\n",
        "\n",
        "        mean = self.mean_linear(x)\n",
        "        log_std = self.log_std_linear(x)\n",
        "        log_std = torch.clamp(log_std, min=self.log_sig_min, max=self.log_sig_max)\n",
        "        std = log_std.exp()\n",
        "        normal = Normal(mean, std)\n",
        "\n",
        "        if deterministic:\n",
        "            pre_tanh_value = mean\n",
        "            action = torch.tanh(mean)\n",
        "        else:\n",
        "            pre_tanh_value = normal.rsample()\n",
        "            action = torch.tanh(pre_tanh_value)\n",
        "\n",
        "        if with_log_prob:\n",
        "            log_prob = normal.log_prob(pre_tanh_value)\n",
        "            log_prob -= torch.log(self.action_scale * (1 - action.pow(2)) + self.action_bound_epsilon)\n",
        "            log_prob = log_prob.sum(1, keepdim=True)\n",
        "        else:\n",
        "            log_prob = None\n",
        "\n",
        "        # Scale the actions\n",
        "        action = action * self.action_scale + self.action_bias\n",
        "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
        "\n",
        "        return (action, mean, log_std, log_prob, std, pre_tanh_value)\n",
        "\n",
        "    def weights_init_(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "            torch.nn.init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gcmZUXUc9Wq"
      },
      "source": [
        "## Replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJA5ntN4xiBS"
      },
      "outputs": [],
      "source": [
        "# code implemented from https://github.com/watchernyu/REDQ/blob/main/redq/algos/core.py\n",
        "\n",
        "class ExperienceReplay:\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_space,\n",
        "        action_space,\n",
        "        size\n",
        "    ):\n",
        "\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "        self.observation_1_buffer = np.zeros([size, self.observation_space], dtype=np.float32)\n",
        "        self.observation_2_buffer = np.zeros([size, self.observation_space], dtype=np.float32)\n",
        "        self.actions_buffer = np.zeros([size, self.action_space], dtype=np.float32)\n",
        "        self.rewards_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.done_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.position = 0\n",
        "        self.size = 0\n",
        "        self.max_size = size\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        observation,\n",
        "        action,\n",
        "        reward,\n",
        "        next_observation,\n",
        "        done\n",
        "    ):\n",
        "\n",
        "        self.observation_1_buffer[self.position] = observation\n",
        "        self.observation_2_buffer[self.position] = next_observation\n",
        "        self.actions_buffer[self.position] = action\n",
        "        self.rewards_buffer[self.position] = reward\n",
        "        self.done_buffer[self.position] = done\n",
        "\n",
        "        self.position = (self.position + 1) % self.max_size\n",
        "\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "\n",
        "    def sample_batch(\n",
        "        self,\n",
        "        batch_size,\n",
        "        idxs=None\n",
        "    ):\n",
        "        if idxs is None:\n",
        "            idxs = np.random.randint(0, self.size, size=batch_size)\n",
        "\n",
        "        return dict(observation_1=self.observation_1_buffer[idxs],\n",
        "                    observation_2=self.observation_2_buffer[idxs],\n",
        "                    actions=self.actions_buffer[idxs],\n",
        "                    rewards=self.rewards_buffer[idxs],\n",
        "                    done=self.done_buffer[idxs],\n",
        "                    idxs=idxs\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJHtclV_30Re"
      },
      "source": [
        "**Reinforcement learning agent**\n",
        "\n",
        "Agent REDQ-SAC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jXNHP8_U-rn"
      },
      "outputs": [],
      "source": [
        "# code implemented from https://github.com/watchernyu/REDQ/blob/main/redq/algos/redq_sac.py\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_space,\n",
        "        action_space,\n",
        "        maximum_action,\n",
        "        hidden_dimensions,\n",
        "        hidden_activation,\n",
        "        action_bound_epsilon,\n",
        "        log_sig_min,\n",
        "        log_sig_max,\n",
        "        N,\n",
        "        M,\n",
        "        G,\n",
        "        replay_size,\n",
        "        batch_size,\n",
        "        alpha,\n",
        "        gamma,\n",
        "        polyak,\n",
        "        random_action_steps,\n",
        "        policy_update_delay,\n",
        "        learning_rate,\n",
        "        device\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "        self.maximum_action = maximum_action\n",
        "        self.hidden_dimensions = hidden_dimensions\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.action_bound_epsilon = action_bound_epsilon\n",
        "        self.log_sig_min = log_sig_min\n",
        "        self.log_sig_max = log_sig_max\n",
        "\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "        self.G = G\n",
        "\n",
        "        self.replay_size = replay_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.polyak = polyak\n",
        "\n",
        "        self.random_action_steps = random_action_steps\n",
        "        self.delay_update_steps = self.random_action_steps\n",
        "        self.policy_update_delay = policy_update_delay\n",
        "        self.target_entropy = -self.maximum_action\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "        # NETWORKS\n",
        "        self.policy_network = D2RLGaussianPolicy(\n",
        "            num_inputs=self.observation_space,\n",
        "            num_actions=self.action_space,\n",
        "            maximum_action=self.maximum_action,\n",
        "            hidden_dim=self.hidden_dimensions,\n",
        "            hidden_activation=self.hidden_activation,\n",
        "            action_bound_epsilon=self.action_bound_epsilon,\n",
        "            log_sig_min=self.log_sig_min,\n",
        "            log_sig_max=self.log_sig_max,\n",
        "            act_space=env.action_space,\n",
        "        ).to(device)\n",
        "\n",
        "\n",
        "        self.q_networks_list, self.q_target_networks_list = [], []\n",
        "        for q_i in range(self.N):\n",
        "            new_q_net = D2RLQNetwork(\n",
        "                num_inputs=self.observation_space,\n",
        "                num_actions=self.action_space,\n",
        "                hidden_dim=self.hidden_dimensions,\n",
        "            ).to(device)\n",
        "            self.q_networks_list.append(new_q_net)\n",
        "\n",
        "            new_q_target_network = D2RLQNetwork(\n",
        "                num_inputs=self.observation_space,\n",
        "                num_actions=self.action_space,\n",
        "                hidden_dim=self.hidden_dimensions,\n",
        "            ).to(device)\n",
        "            new_q_target_network.load_state_dict(new_q_net.state_dict())\n",
        "            self.q_target_networks_list.append(new_q_target_network)\n",
        "\n",
        "        # OPTIMIZERS\n",
        "        self.policy_optimizer = optim.Adam(self.policy_network.parameters(), lr=self.learning_rate)\n",
        "        self.q_optimizer_list = []\n",
        "        for q_i in range(self.N):\n",
        "            self.q_optimizer_list.append(optim.Adam(self.q_networks_list[q_i].parameters(), lr=self.learning_rate))\n",
        "\n",
        "\n",
        "        self.log_alpha = torch.zeros(1, requires_grad=True, device=device)\n",
        "        self.alpha_optim = optim.Adam([self.log_alpha], lr=self.learning_rate)\n",
        "        self.alpha = self.log_alpha.cpu().exp().item()\n",
        "\n",
        "        # EXPERIENCE REPLAY\n",
        "        self.experience_replay = ExperienceReplay(\n",
        "            observation_space=self.observation_space,\n",
        "            action_space=self.action_space,\n",
        "            size=self.replay_size\n",
        "        )\n",
        "\n",
        "        # LOSS\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def __get_current_num_data(self):\n",
        "        return self.experience_replay.size\n",
        "\n",
        "\n",
        "    def get_exploration_action(\n",
        "        self,\n",
        "        observation,\n",
        "        env\n",
        "    ):\n",
        "        with torch.no_grad():\n",
        "            if self.__get_current_num_data() > self.random_action_steps:\n",
        "                observation_tensor = torch.Tensor(observation).unsqueeze(0).to(self.device)\n",
        "                action_tensor = self.policy_network.forward(observation_tensor, deterministic=False, with_log_prob=False)[0]\n",
        "                action = action_tensor.cpu().numpy().reshape(-1)\n",
        "            else:\n",
        "                action = env.action_space.sample()\n",
        "        return action\n",
        "\n",
        "    def get_test_action(\n",
        "        self,\n",
        "        observation\n",
        "    ):\n",
        "        with torch.no_grad():\n",
        "            observation_tensor = torch.Tensor(observation).unsqueeze(0).to(self.device)\n",
        "            action_tensor = self.policy_network.forward(observation_tensor, deterministic=True, with_log_prob=False)[0]\n",
        "            action = action_tensor.cpu().numpy().reshape(-1)\n",
        "        return action\n",
        "\n",
        "\n",
        "    def get_action_and_logprob_for_bias_evaluation(\n",
        "        self,\n",
        "        observation\n",
        "    ):\n",
        "        with torch.no_grad():\n",
        "            observation_tensor = torch.Tensor(observation).unsqueeze(0).to(self.device)\n",
        "            action_tensor, _, _, log_prob_a_tilda, _, _, = self.policy_network.forward(observation_tensor, deterministic=False, with_log_prob=True)\n",
        "            action = action_tensor.cpu().numpy().reshape(-1)\n",
        "        return action, log_prob_a_tilda\n",
        "\n",
        "\n",
        "    def get_ave_q_prediction_for_bias_evaluation(\n",
        "        self,\n",
        "        observation_tensor,\n",
        "        actions_tensor\n",
        "    ):\n",
        "        q_prediction_list = []\n",
        "        for q_i in range(self.N):\n",
        "            q_prediction = self.q_networks_list[q_i](torch.cat([observation_tensor, actions_tensor], 1))\n",
        "            q_prediction_list.append(q_prediction)\n",
        "        q_prediction_cat = torch.cat(q_prediction_list, dim=1)\n",
        "        average_q_prediction = torch.mean(q_prediction_cat, dim=1)\n",
        "        return average_q_prediction\n",
        "\n",
        "\n",
        "    def store_data(\n",
        "        self,\n",
        "        observation,\n",
        "        action,\n",
        "        reward,\n",
        "        new_observation,\n",
        "        done\n",
        "    ):\n",
        "        self.experience_replay.store(observation, action, reward, new_observation, done)\n",
        "\n",
        "\n",
        "    def sample_data(\n",
        "        self,\n",
        "        batch_size\n",
        "    ):\n",
        "        batch = self.experience_replay.sample_batch(batch_size)\n",
        "        observation_tensor = torch.Tensor(batch[\"observation_1\"]).to(self.device)\n",
        "        observation_next_tensor = torch.Tensor(batch[\"observation_2\"]).to(self.device)\n",
        "        actions_tensor = torch.Tensor(batch[\"actions\"]).to(self.device)\n",
        "        rewards_tensor = torch.Tensor(batch[\"rewards\"]).unsqueeze(1).to(self.device)\n",
        "        done_tensor = torch.Tensor(batch[\"done\"]).unsqueeze(1).to(self.device)\n",
        "        return observation_tensor, observation_next_tensor, actions_tensor, rewards_tensor, done_tensor\n",
        "\n",
        "\n",
        "    def get_probabilistic_Ms(\n",
        "        self,\n",
        "        Ms\n",
        "    ):\n",
        "        floored_Ms = np.floor(Ms)\n",
        "        if Ms - floored_Ms > 0.001:\n",
        "            prob_for_higher_value = Ms - floored_Ms\n",
        "            if np.random.uniform(0, 1) < prob_for_higher_value:\n",
        "                return int(floored_Ms + 1)\n",
        "            else:\n",
        "                return int(floored_Ms)\n",
        "        else:\n",
        "            return Ms\n",
        "\n",
        "\n",
        "    def get_redq_q_target_no_grad(\n",
        "        self,\n",
        "        observation_next_tensor,\n",
        "        rewards_tensor,\n",
        "        done_tensor\n",
        "    ):\n",
        "\n",
        "        Ms_to_use = self.get_probabilistic_Ms(self.M)\n",
        "        sample_idxs = np.random.choice(self.N, Ms_to_use, replace=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            a_tilda_next, _, _, log_prob_a_tilda_next, _, _ = self.policy_network.forward(observation_next_tensor)\n",
        "            q_prediction_next_list = []\n",
        "            for sample_idx in sample_idxs:\n",
        "                q_prediction_next = self.q_target_networks_list[sample_idx](torch.cat([observation_next_tensor, a_tilda_next], 1))\n",
        "                q_prediction_next_list.append(q_prediction_next)\n",
        "            q_prediction_next_cat = torch.cat(q_prediction_next_list, 1)\n",
        "            min_q, min_indices = torch.min(q_prediction_next_cat, dim=1, keepdim=True)\n",
        "            next_q_with_log_prob = min_q - self.alpha * log_prob_a_tilda_next\n",
        "            y_q = rewards_tensor + self.gamma * (1 - done_tensor) * next_q_with_log_prob\n",
        "\n",
        "        return y_q, sample_idxs\n",
        "\n",
        "\n",
        "    def polyak_update_target_network(\n",
        "        self,\n",
        "        model_a,\n",
        "        model_b,\n",
        "        rou\n",
        "    ):\n",
        "        for model_a_param, model_b_param in zip(model_a.parameters(), model_b.parameters()):\n",
        "            model_a_param.data.copy_(rou * model_a_param.data + (1 - rou) * model_b_param.data)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        num_update = 0 if self.__get_current_num_data() <= self.delay_update_steps else self.G\n",
        "        for i_update in range(num_update):\n",
        "            observation_tensor, observation_next_tensor, actions_tensor, rewards_tensor, done_tensor = self.sample_data(self.batch_size)\n",
        "\n",
        "            # Q LOSS\n",
        "            y_q, sample_idxs = self.get_redq_q_target_no_grad(observation_next_tensor, rewards_tensor, done_tensor)\n",
        "            q_prediction_list = []\n",
        "            for q_i in range(self.N):\n",
        "                q_prediction = self.q_networks_list[q_i](torch.cat([observation_tensor, actions_tensor], 1))\n",
        "                q_prediction_list.append(q_prediction)\n",
        "            q_prediction_cat = torch.cat(q_prediction_list, dim=1)\n",
        "            y_q = y_q.expand((-1, self.N)) if y_q.shape[1] == 1 else y_q\n",
        "            q_loss_all = self.loss(q_prediction_cat, y_q) * self.N\n",
        "\n",
        "            for q_i in range(self.N):\n",
        "                self.q_optimizer_list[q_i].zero_grad()\n",
        "            q_loss_all.backward()\n",
        "\n",
        "            # POLICY LOSS\n",
        "            if ((i_update + 1) % self.policy_update_delay == 0) or i_update == num_update - 1:\n",
        "                # get policy loss\n",
        "                a_tilda, mean_a_tilda, log_std_a_tilda, log_prob_a_tilda, _, pretanh = self.policy_network.forward(observation_tensor)\n",
        "                q_a_tilda_list = []\n",
        "                for sample_idx in range(self.N):\n",
        "                    self.q_networks_list[sample_idx].requires_grad_(False)\n",
        "                    q_a_tilda = self.q_networks_list[sample_idx](torch.cat([observation_tensor, a_tilda], 1))\n",
        "                    q_a_tilda_list.append(q_a_tilda)\n",
        "                q_a_tilda_cat = torch.cat(q_a_tilda_list, 1)\n",
        "                ave_q = torch.mean(q_a_tilda_cat, dim=1, keepdim=True)\n",
        "                policy_loss = (self.alpha * log_prob_a_tilda - ave_q).mean()\n",
        "                self.policy_optimizer.zero_grad()\n",
        "                policy_loss.backward()\n",
        "                for sample_idx in range(self.N):\n",
        "                    self.q_networks_list[sample_idx].requires_grad_(True)\n",
        "\n",
        "                # ALPHA LOSS\n",
        "                alpha_loss = -(self.log_alpha * (log_prob_a_tilda + self.target_entropy).detach()).mean()\n",
        "                self.alpha_optim.zero_grad()\n",
        "                alpha_loss.backward()\n",
        "                self.alpha_optim.step()\n",
        "                self.alpha = self.log_alpha.cpu().exp().item()\n",
        "\n",
        "\n",
        "            for q_i in range(self.N):\n",
        "                self.q_optimizer_list[q_i].step()\n",
        "\n",
        "            if ((i_update + 1) % self.policy_update_delay == 0) or i_update == num_update - 1:\n",
        "                self.policy_optimizer.step()\n",
        "\n",
        "            for q_i in range(self.N):\n",
        "                self.polyak_update_target_network(self.q_target_networks_list[q_i], self.q_networks_list[q_i], self.polyak)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdeCP_LdeMAq"
      },
      "source": [
        "Hyperparameters and settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRVRWQC1eOJ4"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters and settings\n",
        "hidden_dimensions = 256 # (256, 256) # Tuple of integers representing the number of neurons in each hidden layer of the neural networks\n",
        "hidden_activation = F.relu # Activation function used for the hidden layers of the neural networks\n",
        "action_bound_epsilon = 0.000001 # A small number used to prevent division by zero\n",
        "log_sig_min = -20 # The minimum value for the logarithm of the standard deviation of the action distribution\n",
        "log_sig_max = 2 # The maximum value for the logarithm of the standard deviation of the action distribution\n",
        "\n",
        "N = 5 # The number of Q-networks used for the REDQ algorithm\n",
        "M = 2 # The number of Q-values used for the REDQ algorithm at each iteration\n",
        "G = 10 # The ratio of updates to environment steps used for the REDQ algorithm\n",
        "\n",
        "replay_size = 1_000_000 # The size of the replay buffer used for experience replay\n",
        "batch_size = 256 # The number of samples taken from the replay buffer for each training iteration\n",
        "\n",
        "random_action_steps = 4_000 # The number of steps during which the agent takes random actions\n",
        "policy_update_delay = 40 # The frequency with which the policy network is updated\n",
        "\n",
        "alpha = 0.2 # The temperature parameter used for the policy's entropy term\n",
        "gamma = 0.99 # The discount factor for future rewards\n",
        "polyak = 0.995 # The polyak averaging parameter used to update the target networks\n",
        "\n",
        "learning_rate = 0.0003 # The learning rate used for the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEv4ZjXmyrHo"
      },
      "source": [
        "**Prepare the environment and wrap it to capture statistics, logs, and videos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "1Xrcek4hxDXl",
        "outputId": "1325b1f8-a826-4606-e2cd-a24b4268fee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The device is: cpu (as recommended)\n",
            "actions are continuous with 4 dimensions/#actions\n",
            "observations are continuous with 24 dimensions/#observations\n",
            "maximum timesteps is: None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = rld.make(\"rldurham/Walker\", render_mode=\"rgb_array\")\n",
        "# env = rld.make(\"rldurham/Walker\", render_mode=\"rgb_array\", hardcore=True) # only attempt this when your agent has solved the non-hardcore version\n",
        "\n",
        "# get statistics, logs, and videos\n",
        "env = rld.Recorder(\n",
        "    env,\n",
        "    smoothing=10,                       # track rolling averages (useful for plotting)\n",
        "    video=True,                         # enable recording videos\n",
        "    video_folder=\"videos\",              # folder for videos\n",
        "    video_prefix=\"xhjd62-agent-video\",  # prefix for videos (replace xxxx00 with your username)\n",
        "    logs=True,                          # keep logs\n",
        ")\n",
        "\n",
        "# training on CPU recommended\n",
        "rld.check_device()\n",
        "\n",
        "# environment info\n",
        "discrete_act, discrete_obs, act_dim, obs_dim = rld.env_info(env, print_out=True)\n",
        "\n",
        "# render start image\n",
        "env.reset(seed=42)\n",
        "rld.render(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieTbssu-7tFN",
        "outputId": "0f1b43f7-8965-4d05-d3f5-558459540974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "# in the submission please use seed_everything with seed 42 for verification\n",
        "seed, observation, info = rld.seed_everything(42, env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6v9Jh198LCn"
      },
      "outputs": [],
      "source": [
        "observation_space = env.observation_space.shape[0]\n",
        "action_space = env.action_space.shape[0]\n",
        "maximum_action = env.action_space.high[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "rDl6ViIDlVOk",
        "outputId": "f8b45179-c5cc-4734-92e6-3106e97bb2ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# initialise agent\n",
        "agent = Agent(\n",
        "    observation_space=observation_space,\n",
        "    action_space=action_space,\n",
        "    maximum_action=maximum_action,\n",
        "    hidden_dimensions=hidden_dimensions,\n",
        "    hidden_activation=hidden_activation,\n",
        "    action_bound_epsilon=action_bound_epsilon,\n",
        "    log_sig_min=log_sig_min,\n",
        "    log_sig_max=log_sig_max,\n",
        "    N=N,\n",
        "    M=M,\n",
        "    G=G,\n",
        "    replay_size=replay_size,\n",
        "    batch_size=batch_size,\n",
        "    alpha=alpha,\n",
        "    gamma=gamma,\n",
        "    polyak=polyak,\n",
        "    random_action_steps=random_action_steps,\n",
        "    policy_update_delay=policy_update_delay,\n",
        "    learning_rate=learning_rate,\n",
        "    device=device\n",
        ")\n",
        "max_episodes = 100\n",
        "max_timesteps = 2000\n",
        "\n",
        "# track statistics for plotting\n",
        "tracker = rld.InfoTracker()\n",
        "\n",
        "# switch video recording off (only switch on every x episodes as this is slow)\n",
        "env.video = False\n",
        "\n",
        "# training procedure\n",
        "for episode in range(max_episodes+1):\n",
        "\n",
        "    # recording statistics and video can be switched on and off (video recording is slow!)\n",
        "    env.info = episode % 10 == 0   # track every x episodes (usually tracking every episode is fine)\n",
        "    env.video = episode % 10 == 0  # record videos every x episodes (set BEFORE calling reset!)\n",
        "\n",
        "    # reset for new episode\n",
        "    observation, info = env.reset()\n",
        "\n",
        "    # run episode\n",
        "    for t in range(max_timesteps):\n",
        "\n",
        "        # select the agent action\n",
        "        # action = agent.sample_action(observation)\n",
        "        action = agent.get_exploration_action(observation, env)\n",
        "\n",
        "        # take action in the environment\n",
        "        # next_observation, reward, done, _ = env.step(action)\n",
        "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        # check whether done\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # remember\n",
        "        agent.store_data(observation, action, reward, next_observation, done)\n",
        "\n",
        "        # Set observation to next observation\n",
        "        observation = next_observation\n",
        "\n",
        "        agent.train()\n",
        "\n",
        "        # stop episode\n",
        "        if done:\n",
        "            break\n",
        "    # write log file (for coursework)\n",
        "    env.write_log(folder=\"logs\", file=\"xhjd62-agent-log.txt\")  # replace xxxx00 with your username\n",
        "\n",
        "    # TRAIN THE AGENT HERE!\n",
        "\n",
        "    # track and plot statistics\n",
        "    tracker.track(info)\n",
        "    # if (episode + 1) % 10 == 0:\n",
        "    tracker.plot(r_mean_=True, r_std_=True, r_sum=dict(linestyle=':', marker='x'))\n",
        "\n",
        "# don't forget to close environment (e.g. triggers last video save)\n",
        "env.close()\n",
        "\n",
        "# write log file (for coursework)\n",
        "env.write_log(folder=\"logs\", file=\"xhjd62-agent-log.txt\")  # replace xxxx00 with your username"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qty5U4HotnMq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz8edf2XtaAZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c7MICoo3Elp"
      },
      "source": [
        "At some I will need to save the model to then reload it and continue training. More info on how to do this here: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8MP4P_o2d09"
      },
      "outputs": [],
      "source": [
        "# will need to save model at some point to then reload and continue training\n",
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "# print(\"Saved PyTorch Model State to model.pth\")\n",
        "\n",
        "# loading the model\n",
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoXN8z1Z9co"
      },
      "source": [
        "A small demo with a predefined heuristic that is suboptimal and has no notion of balance (and is designed for the orignal BipedalWalker environment)..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}